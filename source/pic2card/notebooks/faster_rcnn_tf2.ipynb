{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow import keras\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# from object_detection.utils import label_map_util\n",
    "# from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from mystique.initial_setups import set_graph_and_tensors\n",
    "from mystique.predict_card import PredictCard\n",
    "from mystique.detect_objects import ObjectDetection\n",
    "from mystique.utils import plot_results\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen_graph from saved_model\n",
    "\n",
    "Using the tf2 object detection tools convert the checkpoint (The one works well) to a saved_model format.\n",
    "\n",
    "from this saved_model format, using the below method convert it into a single frozen_graph for easy packaging with application in case of pic2card. There is no dedicated tools available to do this process in tf2 version as it got\n",
    "depricated in tf2 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def = tf.compat.v1.GraphDef()\n",
    "imported = tf.saved_model.load(\n",
    "    \"/home/haridas/projects/opensource/tf-models/research/object_detection/pic2card_model/saved_model/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_fun = imported.signatures['serving_default']\n",
    "frozen_func = convert_variables_to_constants_v2(concrete_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_variables_to_constants_v2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=\"/home/haridas/projects/opensource/tf-models/research/object_detection/pic2card_model/\",\n",
    "                  name=\"frozen_graph1.pb\",\n",
    "                  as_text=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_func.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nodes = [i.name for i in frozen_func.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = frozen_func.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_graph = \"/home/haridas/projects/opensource/tf-models/research/object_detection/pic2card_model/frozen_graph.pb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_frozen_graph(graph_def, inputs, outputs, print_graph=False):\n",
    "    def _imports_graph_def():\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "    wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\n",
    "    import_graph = wrapped_import.graph\n",
    "\n",
    "#     if print_graph == True:\n",
    "#         print(\"-\" * 50)\n",
    "#         print(\"Frozen model layers: \")\n",
    "#         layers = [op.name for op in import_graph.get_operations()]\n",
    "#         for layer in layers:\n",
    "#             print(layer)\n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "    return wrapped_import.prune(\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, inputs),\n",
    "        tf.nest.map_structure(import_graph.as_graph_element, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(frozen_graph, 'rb') as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    loaded = graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_func = wrap_frozen_graph(graph_def=graph_def,\n",
    "                                inputs=[\"input_tensor:0\"],\n",
    "                                outputs=[\"Identity_1:0\", \"Identity_2:0\", \"Identity_4:0\"]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.name for i in frozen_func.graph.get_operations()[-20:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_graph_and_tensors(tensors=(\"detection_boxes\", \"detection_scores\",\n",
    "                                   \"detection_classes\")):\n",
    "    \"\"\"\n",
    "    setting up tf graphs and tensors using the trained inference graph\n",
    "\n",
    "    @param tensors: required tensors from inference graph\n",
    "\n",
    "    :return: detection_graph, category_index, tensor_dict\n",
    "    \"\"\"\n",
    "    tensor_dict = dict()\n",
    "    detection_graph = tf.Graph()\n",
    "    # setting up default graph with graphs from inference graph\n",
    "    with detection_graph.as_default() as default_graph:\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.compat.v1.gfile.GFile(\n",
    "            config.TF_FROZEN_MODEL_PATH, \"rb\"\n",
    "        ) as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name=\"\")\n",
    "        ops = default_graph.get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        for tensor in tensors:\n",
    "            tmp_tensor_name = tensor + \":0\"\n",
    "            if tmp_tensor_name in all_tensor_names:\n",
    "                tensor_dict[tensor] = default_graph.get_tensor_by_name(\n",
    "                    tmp_tensor_name\n",
    "                )\n",
    "\n",
    "    return detection_graph, tensor_dict\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(self, image: np.array):\n",
    "    \"\"\"\n",
    "    Runs the inference graph for the given image\n",
    "    @param image: numpy array of input design image\n",
    "    @return: output dict of objects, classes and coordinates\n",
    "    \"\"\"\n",
    "    # Run inference\n",
    "    detection_graph = self.detection_graph\n",
    "    with detection_graph.as_default():\n",
    "        image_tensor = detection_graph.get_tensor_by_name(\n",
    "            \"image_tensor:0\")\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            output_dict = sess.run(\n",
    "                self.tensor_dict, feed_dict={\n",
    "                    image_tensor: np.expand_dims(\n",
    "                        image, 0)})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as\n",
    "    # appropriate\n",
    "    output_dict[\"detection_classes\"] = output_dict[\n",
    "        \"detection_classes\"][0].astype(np.uint8)\n",
    "    output_dict[\"detection_boxes\"] = output_dict[\n",
    "        \"detection_boxes\"][0]\n",
    "    output_dict[\"detection_scores\"] = output_dict[\n",
    "        \"detection_scores\"][0]\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/3.png\"\n",
    "img = Image.open(img_path)\n",
    "img_np = np.asarray(img)\n",
    "img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.datasets.fashion_mnist.load_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(tf.constant(img_np), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes, labels, scores = frozen_func(input_tensor=tf.expand_dims(tf.constant(img_np), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_outputs[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bbox(img_path) -> np.array:\n",
    "    \"\"\"\n",
    "    Predict the bounding boxes, class label and draw the bbox\n",
    "    on the original image.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img_np = np.asarray(img)\n",
    "    img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "    #img_np_copy = img_np.copy()\n",
    "    object_detection = ObjectDetection()\n",
    "    \n",
    "    output = object_detection.get_objects(img_np, img)\n",
    "    # google models wants ymin, xmin, ymax, xmax format.\n",
    "    # output[\"detection_boxes\"] = output[\"detection_boxes\"][:, [1, 0, 3, 2]]\n",
    "    \n",
    "    # print(output.keys())\n",
    "    \n",
    "    _img = plot_results(img,\n",
    "                 output[\"detection_classes\"],\n",
    "                 output[\"detection_scores\"],\n",
    "                 output[\"detection_boxes\"]\n",
    "                )\n",
    "    return _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/3.png\"\n",
    "\n",
    "Image.open(predict_bbox(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/haridas/projects/AdaptiveCards-ro/source/pic2card/app/assets/samples/1.png\"\n",
    "Image.open(predict_bbox(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Graph Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, gconf = set_graph_and_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCNN and Family\n",
    "\n",
    "Inspect the different aspect of the RCNN family of models and debug and tune them based on the\n",
    "necessity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor box generation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/haridas/projects/AdaptiveCards/source/pic2card/out/frcnn-2020-07-05-1593958532/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = tf.train.latest_checkpoint(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
